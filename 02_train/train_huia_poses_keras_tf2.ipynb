{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Huia Experience Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup \n",
    "## Install Tensorflow 2 Nightly and other Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf addons only works with alpha for now\n",
    "\n",
    "#!pip install tensorflow-gpu==2.0.0-alpha0 \n",
    "#!pip install tensorflowjs=2.0.0-alpha0\n",
    "\n",
    "#!pip install fastai=1.0.52\n",
    "#!pip install tensorflow-addons\n",
    "#!pip install opencv-python\n",
    "#!pip install scipy\n",
    "#!pip install sklearn\n",
    "\n",
    "#!pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190305 --force-reinstall \n",
    "#!pip install tensorflow-gpu==2.0.0-alpha0  --force-reinstall\n",
    "#!pip install tensorflowjs==1.0.1 --force-reinstall\n",
    "\n",
    "#!pip install tf-nightly-gpu-2.0-preview --upgrade --force-reinstall\n",
    "#!pip install pathlib\n",
    "#!pip install matplotlib\n",
    "!pip freeze | egrep 'tensor|tb|tf|numpy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import tensorflowjs as tfjs\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "#import tensorflow_addons as tfa # not used for now as it is incompatible with tf.data.Dataset\n",
    "\n",
    "# enable logging to make sure we are running on the GPU\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# check tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clear any active session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We have to understand well our data as this is fundamental to achieve good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = pathlib.Path(\"./training_data/\")\n",
    "image_path = root_path /\"images\"\n",
    "json_path = root_path /\"json\"\n",
    "augmented_path = root_path/\"augmented_imgs\"\n",
    "\n",
    "image_path,json_path ,augmented_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set the random seed so we can reproduce our results\n",
    "random.seed(7)\n",
    "\n",
    "# get filenames from directories \n",
    "all_image_paths = list(image_path.glob('*.png')) + list(augmented_path.glob('*.png'))\n",
    "#all_json_paths = list(json_path.glob('*.json'))\n",
    "\n",
    "all_image_paths = [str(path) for path in all_image_paths] # convert to strings\n",
    "random.shuffle(all_image_paths) # randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_image_paths)#, len(all_json_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# extract categories for classification\n",
    "pat = r'/([^/]+)_\\d+.png$'\n",
    "all_image_labels = [str(re.search(pat,str(image)).group(1)).lower() for image in all_image_paths]\n",
    "len(all_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lets check samples of our images to see what they look like\n",
    "for n in range(3):  \n",
    "    image = random.choice(all_image_paths)\n",
    "    display.display(display.Image(str(image)))\n",
    "    print(f\"file: {image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique classes\n",
    "huia_person=[]\n",
    "for label in all_image_labels:\n",
    "    if label not in huia_person:\n",
    "        huia_person.append(label)\n",
    "huia_person = sorted(huia_person) # sort label list\n",
    "huia_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put them in a dict for lookup\n",
    "label_to_index = dict((name, index) for index,name in enumerate(huia_person))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets format it, so we can copy and paste the dict direclty into javascript :-)\n",
    "print(\"POSE_CLASSES = {\")\n",
    "for index,name in enumerate(huia_person):\n",
    "    print(\"\\t\" +str(index)+\": '\"+name+\"',\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into tf data\n",
    "img_raw = tf.io.read_file(all_image_paths[0])\n",
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)\n",
    "plt.imshow(img_tensor)\n",
    "\n",
    "#img_raw.numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "#@tf.function\n",
    "def  preprocess_image(image):\n",
    "    #print(\"EagerMode:\" + str(tf.executing_eagerly()))\n",
    "    # decode PNG\n",
    "    image = tf.image.decode_png(image, channels=3)    \n",
    "    \n",
    "    # data augmentation - doing statically via fastai, as tensorflow addons is not compatible with graph mode yet \n",
    "    # rotate random\n",
    "    #degrees = random.randint(-6,6)\n",
    "    #angle = degrees * math.pi / 180\n",
    "    #image = tfa.image.rotate(image,angle,interpolation='BILINEAR')\n",
    "    # comented as this is not supported in graph mode yet\n",
    "    \n",
    "    # random crop - images are tensors of shape (500,640,3)\n",
    "    #crop_factor = (random.randint(0,20)/100) # generate numbers between 0.7 and 1.0\n",
    "    #new_width = int(640 * (1-crop_factor))\n",
    "    #new_height = int(500 * (1-crop_factor))\n",
    "    # resize_image_with_crop_or_pad\n",
    "    # image = tf.image.resize_image_with_crop_or_pad(image,new_height,new_width)\n",
    "    # commented as we are doing prepocessing on static files\n",
    "    \n",
    "    # resize\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "\n",
    "    # normalize = convert to [-1:1]    \n",
    "    offset = 127.5\n",
    "    image = (image-offset)/offset\n",
    "    return image\n",
    "\n",
    "#@tf.function\n",
    "def load_and_preprocess_image(path):    \n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into tf data\n",
    "img_tensor = load_and_preprocess_image(all_image_paths[0])\n",
    "plt.imshow(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "path_ds\n",
    "\n",
    "next(iter(path_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force non performatic eager mode as tfa.image doesn't support graph mode yet\n",
    "#image_ds = path_ds.map(lambda path: tf.py_function(func=load_and_preprocess_image,inp=[path],Tout=tf.float32))\n",
    "image_ds = path_ds.map(map_func=load_and_preprocess_image,num_parallel_calls = AUTOTUNE).cache(filename='images_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_labels_idx = [label_to_index[label] for label in all_image_labels]\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels_idx, tf.int64))\n",
    "len(all_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "image_label_ds\n",
    "image_count = len(all_image_labels)\n",
    "\n",
    "type(image_label_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = image_label_ds.cache()\n",
    "ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a pretrained mobilenet for transferlearning\n",
    "mobilenet = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
    "mobilenet.trainable = False\n",
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(ds))\n",
    "print(image_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch[0].numpy()\n",
    "image_batch[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(ds))\n",
    "\n",
    "feature_map_batch = mobilenet(image_batch)\n",
    "print(feature_map_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    mobilenet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1024,activation='relu',bias_initializer=tf.keras.initializers.he_normal()),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1024,activation='relu',bias_initializer=tf.keras.initializers.he_normal()),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512,activation='relu',bias_initializer=tf.keras.initializers.he_normal(),name='features'),\n",
    "    tf.keras.layers.Dense(len(huia_person),activation='softmax'),\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HuiaModel(tf.keras.Model):\n",
    "#     def __init__(self):\n",
    "#         super(HuiaModel,self).__init__()\n",
    "#         self.mobilenet = mobilenet\n",
    "#         self.globalavg = tf.keras.layers.GlobalAveragePooling2D()\n",
    "#         self.drop1 = tf.keras.layers.Dropout(0.3)\n",
    "#         self.dense1 = tf.keras.layers.Dense(1024,activation='relu',bias_initializer=tf.keras.initializers.he_normal())\n",
    "#         self.drop2 = tf.keras.layers.Dropout(0.3)\n",
    "#         self.dense2 = tf.keras.layers.Dense(1024,activation='relu',bias_initializer=tf.keras.initializers.he_normal())\n",
    "#         self.drop3 = tf.keras.layers.Dropout(0.2)\n",
    "#         self.dense3 = tf.keras.layers.Dense(512,activation='relu',bias_initializer=tf.keras.initializers.he_normal(),name='features')\n",
    "#         self.softmax = tf.keras.layers.Dense(len(huia_person),activation='softmax')\n",
    "    \n",
    "#     def call(self,x):\n",
    "#         x = self.mobilenet(x)\n",
    "#         x = self.globalavg(x)\n",
    "#         x = self.drop1(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.drop2(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.drop3(x)\n",
    "#         x = self.dense3(x)\n",
    "#         return self.softmax(x)\n",
    "\n",
    "# max_lr = 3e-4\n",
    "\n",
    "# model = HuiaModel()\n",
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=max_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-07, amsgrad=False)\n",
    "\n",
    "# train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "# train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "# test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "# test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def train_step(images, labels):\n",
    "#   with tf.GradientTape() as tape:\n",
    "#     predictions = model(images)\n",
    "#     loss = loss_object(labels, predictions)\n",
    "#   gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#   optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "#   train_loss(loss)\n",
    "#   train_accuracy(labels, predictions)\n",
    "    \n",
    "# @tf.function\n",
    "# def test_step(images, labels):\n",
    "#   predictions = model(images)\n",
    "#   t_loss = loss_object(labels, predictions)\n",
    "\n",
    "#   test_loss(t_loss)\n",
    "#   test_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "# EPOCHS = 20\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#   for images, labels in train_ds:\n",
    "#     train_step(images, labels)\n",
    "\n",
    "#   for test_images, test_labels in test_ds:\n",
    "#     test_step(test_images, test_labels)\n",
    "\n",
    "#   template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "#   print (template.format(epoch+1,\n",
    "#                          train_loss.result(),\n",
    "#                          train_accuracy.result()*100,\n",
    "#                          test_loss.result(),\n",
    "#                          test_accuracy.result()*100))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_batch = model(image_batch).numpy()\n",
    "\n",
    "print(\"min logit:\", logit_batch.min())\n",
    "print(\"max logit:\", logit_batch.max())\n",
    "print()\n",
    "\n",
    "print(\"Shape:\", logit_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=tf.math.ceil((len(all_image_paths)-838)/BATCH_SIZE).numpy()\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Cycle https://www.kaggle.com/robotdreams/one-cycle-policy-with-keras\n",
    "# import OneCycleLR\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "log_dir = \"./logs/1_\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "# logging\n",
    "tbCallback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "tbCallback.set_model(model)\n",
    "callbacks.append(tbCallback)\n",
    "\n",
    "epochs = 20\n",
    "max_lr = 3e-4\n",
    "\n",
    "base_lr = max_lr/10\n",
    "# max_m = 0.98\n",
    "# base_m = 0.85\n",
    "\n",
    "# cyclical_momentum = False\n",
    "# augment = True\n",
    "# cycles = 2.35\n",
    "\n",
    "# iterations = round(len(all_image_paths)/BATCH_SIZE*epochs)\n",
    "# iterations = list(range(0,iterations+1))\n",
    "# step_size = len(iterations)/(cycles)\n",
    "\n",
    "# clr = OneCycleLR.CyclicLR(base_lr=base_lr,\n",
    "#                 max_lr=max_lr,\n",
    "#                 step_size=step_size,\n",
    "#                 max_m=max_m,\n",
    "#                 base_m=base_m,\n",
    "#                 cyclical_momentum=cyclical_momentum)\n",
    "\n",
    "#callbacks.append(clr)\n",
    "\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#   def on_epoch_end(self, epoch, logs={}):\n",
    "#     if(logs.get('val_accuracy')>0.9):\n",
    "#       print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "#       self.model.stop_training = True\n",
    "\n",
    "# earlyStopping = tf.keras.callbacks.EarlyStopping(patience=2, monitor='loss')\n",
    "# callbacks.append(earlyStopping)\n",
    "\n",
    "# chkPoint = tf.keras.callbacks.ModelCheckpoint('./models.h5')\n",
    "# chkPoint.set_model(model)\n",
    "# callbacks.append(chkPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip 20% validation images\n",
    "test_dataset = ds.take(838) \n",
    "train_dataset = ds.skip(838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.trainable = False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=max_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-07, amsgrad=False), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=epochs,steps_per_epoch=steps_per_epoch,verbose=1,validation_data=test_dataset,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import OneCycleLR\n",
    "now = datetime.now()\n",
    "log_dir = \"./logs/2_\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "epochs = 50\n",
    "max_lr = 3e-6\n",
    "\n",
    "base_lr = max_lr/10\n",
    "max_m = 0.98\n",
    "base_m = 0.85\n",
    "\n",
    "cyclical_momentum = False\n",
    "augment = True\n",
    "cycles = 2.35\n",
    "\n",
    "iterations = round(len(all_image_paths)/BATCH_SIZE*epochs)\n",
    "iterations = list(range(0,iterations+1))\n",
    "step_size = len(iterations)/(cycles)\n",
    "\n",
    "clr = OneCycleLR.CyclicLR(base_lr=base_lr,\n",
    "                max_lr=max_lr,\n",
    "                step_size=step_size,\n",
    "                max_m=max_m,\n",
    "                base_m=base_m,\n",
    "                cyclical_momentum=cyclical_momentum)\n",
    "\n",
    "#callbacks.append(clr)\n",
    "\n",
    "# logging\n",
    "tbCallback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "tbCallback.set_model(model)\n",
    "callbacks.append(tbCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=max_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-07, amsgrad=False), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=epochs,steps_per_epoch=steps_per_epoch,verbose=1,validation_data=test_dataset,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/huia_mob_224_final9.h5\") # 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TENSORFLOW JS / Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 2 Alpha has a bug exporting to TFJS, so we need to use a nightly version\n",
    "import tensorflowjs as tfjs\n",
    "import numpy as np\n",
    "\n",
    "# model = tf.keras.models.load_model(\"models/huia_mob_224_final_one_cycle.h5\")\n",
    "# model.load_weights(\"models/huia_mob_224_final_one_cycle.h5\")\n",
    "\n",
    "#tfjs.converters.save_keras_model(model, \"models_tfjs/tfjs_huia_mob_224_final9_q16\",quantization_dtype=np.uint16)\n",
    "#tfjs.converters.save_keras_model(model, \"models_tfjs/tfjs_huia_mob_224_final9_q8\",quantization_dtype=np.uint8)\n",
    "\n",
    "# run on command line, above commands are buggy at the moment\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=keras \\\n",
    "    --output_format=tfjs_layers_model \\\n",
    "    ./models/huia_mob_224_final_one_cycle.h5 \\\n",
    "    ./models_tfjs/tfjs_huia_mob_224_final_q16a \\\n",
    "    --quantization_bytes 2\n",
    "\n",
    "\n",
    "# copy tfjs model to 03_experience/static and change App.vue reference to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,'model.png',show_layer_names=False) #,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tensorboard/\n",
    "import tensorboard as tb\n",
    "%load_ext tensorboard.notebook\n",
    "\n",
    "#notebook.list() # View open TensorBoard instances\n",
    "#notebook.display(port=6006, height=1000)\n",
    "#!kill 25264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test / Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sample = np.reshape(img_final,[1,224,224,3])\n",
    "\n",
    "predict = int(model.predict_classes(sample))\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key,value in label_to_index.items() if value == predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Images that are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during image capture some images are empty, so we automatically delete them\n",
    "\n",
    "# open images and delete if they are empty\n",
    "def remove_empty_imgs(imgpath):\n",
    "    for item in imgpath.iterdir():\n",
    "        im = imread(str(item), format='png')\n",
    "        if np.count_nonzero(im)==0: \n",
    "            print(item,np.count_nonzero(im))\n",
    "            os.remove(str(item))\n",
    "            \n",
    "#remove_empty_imgs(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync JSONs with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we might delete unwanted images for training, this will also delete the json files\n",
    "# sync json & images \n",
    "\n",
    "def sync_json_images(json_paths, img_path):\n",
    "    for json in json_paths:\n",
    "        #print(json.stem, end=\" \")\n",
    "        img = img_path/f\"{json.stem}.png\"\n",
    "        if not Path(img).exists():\n",
    "            print(f\"{img} doesn't exist, deleting {json}\")\n",
    "            Path(json).unlink()\n",
    "        \n",
    "#sync_json_images(all_json_paths, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Data Augmentation\n",
    "Decided to use FASTAI to statically preprocess data augmentation, as tensorflow addons (0.3.1) still didn't support graph mode and is therefore not compatible with tf.data.Dataset mappings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from random import randint\n",
    "import pathlib\n",
    "\n",
    "root_path = pathlib.Path(\"./training_data/\")\n",
    "save_fast = Path('./training_data/augmented_imgs/')\n",
    "save_fast.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tfms = get_transforms(do_flip=False, \n",
    "                            flip_vert=False, \n",
    "                            max_rotate=6, \n",
    "                            max_zoom=1.2, \n",
    "                            max_lighting=None, \n",
    "                            max_warp=0.2, \n",
    "                            p_affine=0.2, \n",
    "                            p_lighting=0)\n",
    "\n",
    "\n",
    "image_path = root_path /\"images\"\n",
    "all_image_paths = list(image_path.glob('*.png'))\n",
    "\n",
    "\n",
    "def generate_augmented(qty):\n",
    "    for f in all_image_paths:\n",
    "        image = open_image(f)\n",
    "        for i in range(0,qty):\n",
    "            image_fast = image.apply_tfms(tfms[0])\n",
    "            save_name = str(save_fast) + '/' + f.stem + '99' + str(i) + f.suffix\n",
    "            print(save_name)\n",
    "            image_fast.save(save_name)\n",
    "\n",
    "#generate 10 variations of each image\n",
    "#generate_augmented(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor20]",
   "language": "python",
   "name": "conda-env-tensor20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
