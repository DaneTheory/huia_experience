{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnx\n",
    "#!pip install onnx_tf\n",
    "# pip install -e . https://github.com/onnx/onnx-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/__init__.py:87: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release. Use node.outputs instead.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.13.1', '1.5.0', '1.16.3')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare # install from master\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "tf.__version__ , onnx.__version__, numpy.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.image import imread\n",
    "# img = imread('./training_data/images/hadouken_262.png')\n",
    "# print(type(img))\n",
    "\n",
    "# from PIL import Image\n",
    "# img = Image.open('./training_data/images/hadouken_262.png')\n",
    "# img_input = img.resize((224, 224), Image.ANTIALIAS) # resizes image in-place\n",
    "\n",
    "# # remove channel transparecy\n",
    "\n",
    "# notrans = Image.new(\"RGB\", img_input.size, (255, 255, 255))\n",
    "# notrans.paste(img_input, mask=img_input.split()[3]) # 3 is the alpha channel\n",
    "\n",
    "# #pix = numpy.array(img.getdata()).reshape(img.size[0], img.size[1], 3)\n",
    "# img_input.size[0],img_input.size[1]\n",
    "\n",
    "#imgplot = plt.imshow(img)\n",
    "\n",
    "\n",
    "# import cv2\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# img_raw = tf.io.read_file('./training_data/images/hadouken_262.png')\n",
    "# #with sess.as_default():\n",
    "# input = tf.io.decode_image(img_raw).eval()\n",
    "\n",
    "# im = cv2.LoadImage('./training_data/images/hadouken_262.png')\n",
    "# input = numpy.asarray(im)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# onnx_model = onnx.load(\"huia2.onnx\")  # load onnx model\n",
    "# #output = prepare(onnx_model).run(input)  # run the loaded model\n",
    "# #prepare(onnx_modeln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"huia2.onnx\")  # load onnx model\n",
    "#output = prepare(onnx_model).run(input)  # run the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_rep.export_graph('huia_tensor_gpu.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6f774102ffb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'std' is not defined"
     ]
    }
   ],
   "source": [
    "std[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# convert array order from pytorch to tensorflow\n",
    "img_raw = tf.io.read_file('./training_data/images/backpack_107.png')\n",
    "with tf.Session().as_default():\n",
    "    image = tf.io.decode_image(img_raw,channels=3).eval()\n",
    "    resized_image = tf.image.resize_images(image, [224, 224]).eval()\n",
    "\n",
    "#normalize image\n",
    "#offset = 127.5;\n",
    "#resized_image = (resized_image-offset)/offset  # convert to -1 : 1 \n",
    "\n",
    "\n",
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "mean = imagenet_stats[0]\n",
    "std = imagenet_stats[1]\n",
    "\n",
    "def normalize(x, mean,std):\n",
    "    for i in range(0,2):\n",
    "        x[i] = x[i]-mean[i]/std[i]    \n",
    "    return x\n",
    "\n",
    "print(resized_image/255)\n",
    "\n",
    "norm_image = normalize(resized_image/255,mean,std)\n",
    "#print(norm_image)\n",
    "\n",
    "#print(resized_image[2])\n",
    "\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    "#print(normalize)\n",
    "\n",
    "#resized_image.shape\n",
    "#type(resized_image)\n",
    "\n",
    "# transpose image\n",
    "trans_image =  np.transpose(norm_image, (2, 0, 1))\n",
    "trans_image.shape\n",
    "\n",
    "# create extra dimension\n",
    "exp_img = np.expand_dims(trans_image, axis=0)\n",
    "exp_img.shape\n",
    "\n",
    "#images_nchw = tf.placeholder(tf.float32, [None, 3, 200, 300])\n",
    "#out = tf.transpose([None,resized_image], [0, 2, 3, 1])\n",
    "#print(out.get_shape())\n",
    "#with tf.Session().as_default():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSE_CLASSES =['backpack',\n",
    " 'dramatic',\n",
    " 'fly',\n",
    " 'hadouken',\n",
    " 'moonwalk',\n",
    " 'normal',\n",
    " 'underarm',\n",
    " 'wings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op DynamicSlice in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/common/handler_helper.py:70: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/handlers/backend/pool_mixin.py:187: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/handlers/backend/pool_mixin.py:124: UserWarning: Using the pooling op in compatibility mode.This means your graph cannot be serialized.Please configure your pooling operation to only use paddings that correspond to Tensorflow SAME or VALID padding.\n",
      "  \"correspond to Tensorflow SAME or VALID padding.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/handlers/backend/reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/ale/Dropbox/projects/onnx-tensorflow/onnx_tf/handlers/backend/gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "tf_rep = prepare(onnx_model,device='CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n"
     ]
    }
   ],
   "source": [
    "output = tf_rep.run(exp_img) #.eval()  # run the loaded model\n",
    "print(POSE_CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outputs(_0=array([[  1.2426745,  14.113052 , -23.66965  ,  44.07164  , -14.209565 ,\n",
       "         16.602457 , -29.920212 , -47.434143 ]], dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#import tensorflowjs as tfjs\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "#tfjs.converters.save_keras_model(model, \"models_tfjs/tfjs_huia_mob_224_teste_10_q3\",quantization_dtype=np.uint8)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor13]",
   "language": "python",
   "name": "conda-env-tensor13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
