uy
#%% Change working directory from the workspace root to the ipynb file location. Turn this addition off with the DataScience.changeDirOnImportExport setting
import os
try:
	os.chdir(os.path.join(os.getcwd(), '02_train'))
	print(os.getcwd())
except:
	pass
#%% [markdown]
# # 02 Huia Experience Training
#%% [markdown]
# ### Reference
# https://www.tensorflow.org/alpha/tutorials/load_data/images
#%% [markdown]
# ## TODOS
# - not using variable learning rates => keras extension --- 
# - LRFinder
# - interpret layers visually
# - tensorboard convergence
#%% [markdown]
# # Setup 
# ## Install FastAI

#%%
get_ipython().run_line_magic('reload_ext', 'autoreload')
get_ipython().run_line_magic('autoreload', '2')
get_ipython().run_line_magic('matplotlib', 'inline')


#%%
from fastai.vision import *
from fastai.metrics import error_rate


#%%
bs = 64
import pathlib
from pathlib import Path
#import tensorboard as tb

#%% [markdown]
# # Data
# We have to understand well our data as this is fundamental to achieve good results.

#%%
root_path = pathlib.Path("./training_data/")
image_path = root_path /"images"
json_path = root_path /"json"
image_path,json_path


#%%
# lets set the random seed so we can reproduce our results
import random
random.seed(7)
# get filenames from directories
all_image_paths = list(image_path.glob('*.png'))

#all_image_paths = [path for path in all_image_paths] # convert to strings
#random.shuffle(all_image_paths) # randomize


#%%
type(all_image_paths)
#len(all_image_paths)


#%%
all_image_paths[:20]


#%%
import re
# extract categories for classification
pat = r'/([^/]+)_\d+.png$'
all_image_labels = [str(re.search(pat,str(image)).group(1)).lower() for image in all_image_paths]
all_image_labels


#%%
# include transforms we can use (rotate, warp)
# transforms=[rand_resize_crop(224,1.3,(0.85,1.23),jitter(0.01),perspective_warp(),
#                              rotate(),skew()]

data = ImageDataBunch.from_name_re(image_path, all_image_paths, pat, 
                                   ds_tfms=get_transforms
                                   (do_flip=False, 
                                    flip_vert=False, 
                                    max_rotate=4, 
                                    max_zoom=1.1, 
                                    max_lighting=None, 
                                    max_warp=0.2, 
                                    p_affine=0.3, 
                                    p_lighting=0) ,
                                    size=224, bs=bs
                                  ).normalize(imagenet_stats)


#%%
data.show_batch(rows=3, figsize=(7,6))


#%%
print(data.classes)
len(data.classes),data.c


#%%
# change for mobilenet
learn = cnn_learner(data, models.resnet34, metrics=error_rate)


#%%
learn.model # summary


#%%
learn.lr_find()
#learn.recorder.plot()


#%%
learn.recorder.plot()


#%%
learn.freeze(:-2)


#%%
learn.fit_one_cycle(20,max_lr=1e-02)


#%%
learn.lr_find()
learn.recorder.plot()


#%%
learn.unfreeze()


#%%
learn.fit_one_cycle(20, max_lr=slice(1e-8,1e-7))


#%%
learn.save('fastai_huia_pose')
learn.export('fastai_huia_pose')


#%%
import IPython.display as display
import numpy


#%%
#training_data/images/moonwalk_250.png
img = open_image("training_data/images/moonwalk_250.png")
img.show()
learn.predict(img)

#%% [markdown]
# #Results

#%%
interp = ClassificationInterpretation.from_learner(learn)

losses,idxs = interp.top_losses()

len(data.valid_ds)==len(losses)==len(idxs)


#%%
interp.plot_top_losses(9, figsize=(15,11))
#doc(plot_top_losses)


#%%
doc(interp.plot_top_losses)


#%%
interp.plot_confusion_matrix(figsize=(10,10),dpi=60)


#%%
interp.most_confused(min_val=1)

#%% [markdown]
# # Export to Tensorflow

#%%
learn = learn.load("fastai_huia_pose")
import torch
from torch.autograd import Variable

dummy_input = Variable(torch.randn(1,3,224,224)).cuda()
torch.onnx.export(learn.model, dummy_input, "huia.onnx")


#%%
import onnx
from onnx_tf.backend import prepare
# import tensorflow.compat.v1 as tf
# tf.disable_v2_behavior()



onnx_model = onnx.load("huia.onnx")  # load onnx model
output = prepare(onnx_model).run(input)  # run the loaded model


#%%
# other converters MMdnn / pytorch2keras


#%%
import tensorflow as tf

import tensorflowjs as tfjs
tfjs.converters.save_keras_model(model, "models_tfjs/tfjs_huia_mob_224_teste_10_q3",quantization_dtype=np.uint8)

#%% [markdown]
# # Tensorboard

#%%
get_ipython().run_line_magic('load_ext', 'tensorboard.notebook')

#notebook.list() # View open TensorBoard instances
#notebook.display(port=6006, height=1000)


#%%
#!kill 25264
get_ipython().run_line_magic('tensorboard', '--logdir ./logs')


#%%
import time
default_timeit_steps = 2*steps_per_epoch+1

def timeit(ds, steps=default_timeit_steps):
  overall_start = time.time()
  # Fetch a single batch to prime the pipeline (fill the shuffle buffer),
  # before starting the timer
  it = iter(ds.take(steps+1))
  next(it)

  start = time.time()
  for i,(images,labels) in enumerate(it):
    if i%10 == 0:
      print('.',end='')
  print()
  end = time.time()

  duration = end-start
  print("{} batches: {} s".format(steps, duration))
  print("{:0.5f} Images/s".format(BATCH_SIZE*steps/duration))
  print("Total time: {}s".format(end-overall_start))


#%%
timeit(ds)

#%% [markdown]
# # Predict

#%%
import numpy as np
sample = np.reshape(img_final,[1,224,224,3])

predict = int(model.predict_classes(sample))
predict


#%%
[key for key,value in label_to_index.items() if value == predict]


#%%
label_to_index


